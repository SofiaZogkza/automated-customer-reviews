{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c432ed82",
   "metadata": {},
   "source": [
    "# Goal of Phase 3 - FLAN-T5 Implementation (Simplified)\n",
    "\n",
    "## Input\n",
    "A CSV file (`final.csv`) containing product information and reviews, with columns such as:\n",
    "\n",
    "- `ProductID`, `Product Name`, `Category`, `Brand`, `Ratings`  \n",
    "- `sentiment` (positive/negative)  \n",
    "- `reviews.text`  \n",
    "\n",
    "## Processing\n",
    "For each product cluster:\n",
    "\n",
    "1. Compute **product-level statistics**: average rating, positive/negative review fractions, and number of reviews.  \n",
    "2. Select the **Top 3 products** per cluster based on a score combining high ratings and low negative review fractions.  \n",
    "3. Identify the **product to avoid** (lowest scoring product).  \n",
    "\n",
    "## AI Prompt Construction\n",
    "Create a structured, multi-part prompt instructing the AI to:\n",
    "\n",
    "- Recommend the Top 3 products with key differences.  \n",
    "- Explain why the worst product should be avoided.  \n",
    "- Base all insights **solely on the review data**.  \n",
    "- Format output with category, product details, positive review summaries, and neutral statements for products to avoid.  \n",
    "\n",
    "## Output\n",
    "- Use **FLAN-T5 (`google/flan-t5-small`)** to generate **human-readable, factual buying guides** per cluster.  \n",
    "- Optionally fine-tune the model with **LoRA** on generated articles to improve output consistency.  \n",
    "- Save all articles in a CSV (`generated_articles_flan.csv`) with columns for cluster, cluster summary, and generated article.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230e9fa6",
   "metadata": {},
   "source": [
    "We chose these models because it is instruction tuned, lightweight and supports text to text tasks like summarization and recommendation. This would make it easy to adapt to our product review."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596310f5",
   "metadata": {},
   "source": [
    "M3 - google/ flan -t5- small (very light and easy to run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d199f18e",
   "metadata": {},
   "source": [
    "### 1. Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04a9556a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (2.3.3)\n",
      "Requirement already satisfied: transformers in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (4.57.1)\n",
      "Requirement already satisfied: torch in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (2.9.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from pandas) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: filelock in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: setuptools in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from requests->transformers) (2025.10.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers>=4.44 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (4.57.1)\n",
      "Requirement already satisfied: datasets in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (4.4.1)\n",
      "Requirement already satisfied: peft in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (0.18.0)\n",
      "Requirement already satisfied: accelerate in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (1.11.0)\n",
      "Requirement already satisfied: sentencepiece in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (0.2.1)\n",
      "Requirement already satisfied: filelock in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from transformers>=4.44) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from transformers>=4.44) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from transformers>=4.44) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from transformers>=4.44) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from transformers>=4.44) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from transformers>=4.44) (2025.11.3)\n",
      "Requirement already satisfied: requests in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from transformers>=4.44) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from transformers>=4.44) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from transformers>=4.44) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from transformers>=4.44) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.44) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.44) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.44) (1.2.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: httpx<1.0.0 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: certifi in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: psutil in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from peft) (7.1.3)\n",
      "Requirement already satisfied: torch>=1.13.0 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from peft) (2.9.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from requests->transformers>=4.44) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from requests->transformers>=4.44) (2.5.0)\n",
      "Requirement already satisfied: setuptools in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from torch>=1.13.0->peft) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from torch>=1.13.0->peft) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from torch>=1.13.0->peft) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from torch>=1.13.0->peft) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from jinja2->torch>=1.13.0->peft) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: pyarrow 22.0.0\n",
      "Uninstalling pyarrow-22.0.0:\n",
      "  Successfully uninstalled pyarrow-22.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow\n",
      "  Downloading pyarrow-22.0.0-cp313-cp313-macosx_12_0_arm64.whl.metadata (3.2 kB)\n",
      "Downloading pyarrow-22.0.0-cp313-cp313-macosx_12_0_arm64.whl (34.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.2/34.2 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyarrow\n",
      "Successfully installed pyarrow-22.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas transformers torch\n",
    "!pip install \"transformers>=4.44\" datasets peft accelerate sentencepiece\n",
    "!pip uninstall -y pyarrow\n",
    "!pip install --no-cache-dir pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c395a0e",
   "metadata": {},
   "source": [
    "### 2. Loads libraries and environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc71a517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch, pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dotenv import load_dotenv\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, TrainingArguments, Trainer, DataCollatorForSeq2Seq\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, get_peft_model, PeftModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4eead1",
   "metadata": {},
   "source": [
    "### 3. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6bec5a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              ProductID                                       Product Name  \\\n",
      "0  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
      "1  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
      "2  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
      "3  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
      "4  AVqkIhwDv8e3D1O-lebb  All-New Fire HD 8 Tablet, 8 HD Display, Wi-Fi,...   \n",
      "\n",
      "                                            Category   Brand  Ratings  \\\n",
      "0  Electronics,iPad & Tablets,All Tablets,Fire Ta...  Amazon      5.0   \n",
      "1  Electronics,iPad & Tablets,All Tablets,Fire Ta...  Amazon      5.0   \n",
      "2  Electronics,iPad & Tablets,All Tablets,Fire Ta...  Amazon      5.0   \n",
      "3  Electronics,iPad & Tablets,All Tablets,Fire Ta...  Amazon      4.0   \n",
      "4  Electronics,iPad & Tablets,All Tablets,Fire Ta...  Amazon      5.0   \n",
      "\n",
      "           Cluster sentiment  \\\n",
      "0  Fire HD Tablets  positive   \n",
      "1  Fire HD Tablets  positive   \n",
      "2  Fire HD Tablets  positive   \n",
      "3  Fire HD Tablets  positive   \n",
      "4  Fire HD Tablets  positive   \n",
      "\n",
      "                                        reviews.text  \n",
      "0  This product so far has not disappointed. My c...  \n",
      "1  This product so far has not disappointed. My c...  \n",
      "2  This product so far has not disappointed. My c...  \n",
      "3  This product so far has not disappointed. My c...  \n",
      "4  This product so far has not disappointed. My c...  \n",
      "Index(['ProductID', 'Product Name', 'Category', 'Brand', 'Ratings', 'Cluster',\n",
      "       'sentiment', 'reviews.text'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../outputs/final.csv\"\n",
    "df=pd.read_csv(data_path)\n",
    "\n",
    "print (df.head())\n",
    "print (df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9382544f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a084fa54",
   "metadata": {},
   "source": [
    "### 3. Sets up FLAN-T5 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21ae9e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 6)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-7): 7 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 6)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-7): 7 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name= \"google/flan-t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a155655",
   "metadata": {},
   "source": [
    "Generation helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1850cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_article_flan(prompt: str, \n",
    "                     max_new_tokens: int = 320,\n",
    "                     temperature: float = 0.7) -> str:\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(device)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "          max_new_tokens=max_new_tokens, \n",
    "          do_sample=True,\n",
    "          temperature=temperature,\n",
    "          top_p=0.95,\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0],skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f1214e",
   "metadata": {},
   "source": [
    "Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50546e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prompt = \"\"\"\n",
    "You are a professional analyst who many people rely on. You will receive structured data.\n",
    "\n",
    "Your task:\n",
    "1. Use the information provided in the structured data.\n",
    "2. Recommend the 3 top products for each category.\n",
    "3. Follow this order: category, product, average rating, positive reviews, summary.\n",
    "4. Each summary must be exactly 2 short factual sentences based on the numbers.\n",
    "5. For the products to avoid, write 1 neutral sentence based on data.\n",
    "6. If no summary text is available for a product, write: \"No review text provided.\"\n",
    "\n",
    "Here are example of the structured data:\n",
    "Categories: Cameras\n",
    "Product: Canon PowerShot G7X|Average rating 4.7| Positive reviews: 92.0%| 120 reviews\n",
    "Product: Sony A6000 Kit|Average rating 4.6| Positive reviews: 89.0%| 310 reviews\n",
    "Product: Nikon D3500| Average rating: 4.5| Positive reviews: 87.0%| 280 reviews    \n",
    "Avoid: Kodak PixPro FZ43|Average rating: 3.1| Negative reviews: 45.0%| 566 reviews\n",
    "\n",
    "Example output:\n",
    "Category: Cameras\n",
    "1. Canon PowerShot G7X- 4.7 average rating, 92% positive reviews, 120 reviews.\n",
    "Summary: Reviewers highlight image quality. Customers also mention good ease of use.\n",
    "2. Sony A6000 Kit- 4.6 average rating, 89% positive reviews, 310 reviews. \n",
    "Summary: Many users like the fast performance. They also appreciate the sharp image results.\n",
    "3. Nikon D3500- 4.5 average rating, 87% positive reviews, 280 reviews. \n",
    "Summary: Reviewers value its simple controls. It is often praised for reliable photo quality.\n",
    "Product to avoid: Kodak PixPro FZ43 has a higher share of negative reviews compared to others.\n",
    "    \n",
    "Here is the structured data: \n",
    " {cluster_summary}\n",
    "\n",
    "Now kindly write the article:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d7e519f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ProductID', 'Product Name', 'Category', 'Brand', 'Ratings', 'Cluster',\n",
      "       'sentiment', 'reviews.text'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f958ca5",
   "metadata": {},
   "source": [
    "### 4. Aggregates products per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0891920b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_products_for_cluster(cluster_df: pd.DataFrame, top_n:int=3):\n",
    "    \"\"\"\n",
    "    For a given cluster (many review rows), compute per- product statistics, \n",
    "    then return top 3 products and one \"Product to avoid\"(top_products_df, worst_product_df).\n",
    "\n",
    "    Works with columns in cluster_df:\n",
    "    ['ProductID', 'Product Name', 'Category', 'Brand', 'Ratings', 'Cluster',\n",
    "       'sentiment', 'reviews.text']\n",
    "    \"\"\"\n",
    "    stats=(\n",
    "        cluster_df\n",
    "        .groupby([\"ProductID\", \"Product Name\", \"Category\", \"Brand\"], as_index=False)\n",
    "        .agg(\n",
    "            num_reviews=(\"sentiment\", \"size\"),\n",
    "            avg_rating=(\"Ratings\", \"mean\"), \n",
    "            pos_reviews=(\"sentiment\", lambda s:(s== \"positive\"). sum()),\n",
    "            neg_reviews=(\"sentiment\", lambda s:( s== \"negative\").sum()),\n",
    "        )\n",
    "    )\n",
    "    stats[\"pos_frac\"]=stats[\"pos_reviews\"]/stats[\"num_reviews\"]\n",
    "    stats[\"neg_frac\"]=stats[\"neg_reviews\"]/stats[\"num_reviews\"]\n",
    "\n",
    "    # Score: high rating, few negatives\n",
    "    min_reviews=20\n",
    "    candidates=stats[stats[\"num_reviews\"]>=min_reviews].copy()\n",
    "    if candidates.empty:\n",
    "        candidates=stats.copy()\n",
    "\n",
    "    candidates[\"score\"]=candidates[\"avg_rating\"]*(1-candidates[\"neg_frac\"])\n",
    "\n",
    "    top_df=(\n",
    "        candidates\n",
    "        .sort_values([\"score\", \"pos_frac\"], ascending=[False, False])\n",
    "        .head(top_n)\n",
    "    )\n",
    "    worst_df=(\n",
    "        candidates\n",
    "        .sort_values([\"score\", \"pos_frac\"], ascending=[True, True])\n",
    "        .head(1)\n",
    "    )\n",
    "    \n",
    "    return top_df, worst_df\n",
    "\n",
    "     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfc0a1b",
   "metadata": {},
   "source": [
    "### 5. Builds cluster summary for prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3a3ef83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_block(row)-> str:\n",
    "    \"\"\"Turn one product row into a text snippet for the prompt.\"\"\"\n",
    "    return (\n",
    "        f\"-Product:{row[\"Product Name\"]} (Brand:{row[\"Brand\"]})\\n\"\n",
    "        f\"  -Average rating: {row[\"avg_rating\"]:.2f} from{int(row[\"num_reviews\"])} review.\\n\"\n",
    "        f\"  -Positive reviews: {row[\"pos_frac\"]*100:.1f}%.\\n\"\n",
    "    )\n",
    "\n",
    "def build_cluster_summary(cluster_name:str,\n",
    "                          top_df:pd.DataFrame,\n",
    "                          worst_df:pd.DataFrame)-> str:\n",
    "    \"\"\" Create the {cluster_summary} text that goes into the prompt.\"\"\"\n",
    "    parts=[]\n",
    "    parts.append(f\"Category:{cluster_name}\\n\")\n",
    "    parts.append(\"Top products:\\n\")\n",
    "    \n",
    "    for _, row in top_df.iterrows():\n",
    "        parts.append(product_block(row))\n",
    "        parts.append(\"\\n\")\n",
    "        \n",
    "    parts.append(\"\\nProduct to avoid:\\n\")\n",
    "    for _, row in worst_df.iterrows():\n",
    "        parts.append(product_block(row))\n",
    "\n",
    "    return\"\\n\".join(parts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2b1aa8",
   "metadata": {},
   "source": [
    "### 6. Full loop: Generate article for every cluster\n",
    "\n",
    "- For each cluster, selects top/worst products, builds prompt, generates text with FLAN-T5, and stores it.\n",
    "\n",
    "- Saves all articles to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "475ea4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Generating article for Cluster Cluster Batteries ===\n",
      "Summary: AmazonBasics AAA Performance Alkaline Batteries (48 Count) is rated 4.45. \n",
      "---\n",
      "\n",
      "\n",
      "=== Generating article for Cluster Cluster Classic Fire Tablets ===\n",
      "Amazon Kindle Fire 16gb 7 Ips Display Tablet is the only one that has a 4.72 rating. \n",
      "---\n",
      "\n",
      "\n",
      "=== Generating article for Cluster Cluster Fire HD Tablets ===\n",
      "Product: Fire HD 8 Tablet, 8\" HD Display, Wi-Fi, 32 GB - Includes Special Offers, Magenta \n",
      "---\n",
      "\n",
      "\n",
      "=== Generating article for Cluster Cluster Kindle E-readers ===\n",
      "3 of the 5 Amazon Kindle Fire E-readers are the best and most expensive. \n",
      "---\n",
      "\n",
      "\n",
      "=== Generating article for Cluster Cluster Smart Home / Audio ===\n",
      "Amazon Fire Hd 10 Tablet, Wi-Fi, 16 Gb, Special Offers - Silver Aluminum - Amazon Fire Hd 10 Tablet, Wi-Fi, 16 Gb, Special Offers - Silver Aluminum - Amazon Fire Hd 10 Tablet, Wi-Fi, 16 Gb, Special Offers - Silver Aluminum - Amazon Fire Hd 10 Tablet, Wi-Fi, 16 Gb, Special Offers - Silver Aluminum - Amazon Fire Hd 10 Tablet, Wi-Fi, 16 Gb, Special Offers - Silver Aluminum \n",
      "---\n",
      "\n",
      "Saved 5 articles to ../deliverables/generated_articles_flan.csv\n",
      "articles_df columns: Index(['cluster_value', 'cluster_name', 'cluster_summary', 'article'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "articles = []\n",
    "\n",
    "for cluster_value,cluster_df in df.groupby(\"Cluster\"):\n",
    "\n",
    "    # Get a human-readable summary of the cluster\n",
    "    cluster_name = f\"Cluster {cluster_value}\"\n",
    "    \n",
    "    # Select top and worst products in a cluster\n",
    "    top_df, worst_df = select_products_for_cluster(cluster_df, top_n=3)\n",
    "\n",
    "    # Build text summary for the cluster\n",
    "    cluster_summary = build_cluster_summary(cluster_name, top_df, worst_df)\n",
    "\n",
    "    # Build prompt\n",
    "    prompt = base_prompt.format(cluster_summary=cluster_summary)\n",
    "    \n",
    "    print(f\"\\n=== Generating article for Cluster {cluster_name} ===\")\n",
    "    article_text = generate_article_flan(prompt)\n",
    "\n",
    "    # Store result\n",
    "    articles.append({\n",
    "        \"cluster_value\": cluster_value,\n",
    "        \"cluster_name\": cluster_name,\n",
    "        \"cluster_summary\": cluster_summary,\n",
    "        \"article\": article_text,\n",
    "    })\n",
    "\n",
    "    # Show a preview of the article\n",
    "    print(article_text[:400], \"\\n---\\n\")\n",
    "\n",
    "articles_df = pd.DataFrame(articles)\n",
    "articles_df.to_csv(\"../deliverables/generated_articles_flan.csv\", index=False)\n",
    "\n",
    "print(\"Saved\", len(articles_df), \"articles to ../deliverables/generated_articles_flan.csv\")\n",
    "print(\"articles_df columns:\",articles_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846de993",
   "metadata": {},
   "source": [
    "### 7. LoRA Fine-tuning\n",
    "\n",
    "- Fine-tunes FLAN-T5 using LoRA on the generated articles dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f627684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 688,128 || all params: 77,649,280 || trainable%: 0.8862\n"
     ]
    }
   ],
   "source": [
    "model_name= \"google/flan-t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "#LoRA configuration\n",
    "peft_config=LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=[\"q\",\"v\"],\n",
    "    task_type=\"SEQ_2_SEQ_LM\",\n",
    ")\n",
    "\n",
    "model= get_peft_model(base_model,peft_config)\n",
    "model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e3f48436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "article_df columns: Index(['cluster_value', 'cluster_name', 'cluster_summary', 'article'], dtype='object')\n",
      "base_df columns: Index(['cluster_value', 'cluster_name', 'input_text', 'target_text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"article_df columns:\",articles_df.columns)\n",
    "\n",
    "base_df=articles_df.copy().rename(columns={\n",
    "    \"cluster_summary\":\"input_text\",\n",
    "    \"article\":\"target_text\",\n",
    "    })\n",
    "    \n",
    "print(\"base_df columns:\",base_df.columns)\n",
    "\n",
    "train_df,val_df=train_test_split(base_df,test_size=0.1,random_state=42)\n",
    "\n",
    "train_ds=Dataset.from_pandas(train_df.reset_index(drop=True))\n",
    "val_ds=Dataset.from_pandas(val_df.reset_index(drop=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4107a01f",
   "metadata": {},
   "source": [
    "Tokenizer and Preprocess function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "80d618d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/4 [00:00<?, ? examples/s]/Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages/transformers/tokenization_utils_base.py:4034: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 4/4 [00:00<00:00, 210.93 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 262.06 examples/s]\n"
     ]
    }
   ],
   "source": [
    "max_input_len=512\n",
    "max_target_len=256\n",
    "\n",
    "def preprocess(batch):\n",
    "    # \n",
    "    inputs=[\n",
    "        \"Write a short, neutral, helpful buying guide from this structured data :\\n\"\n",
    "        +t\n",
    "        for t in batch[\"input_text\"]\n",
    "    ]\n",
    "    model_inputs=tokenizer(\n",
    "        inputs,\n",
    "        max_length=max_input_len,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"np\"\n",
    "    )\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels=tokenizer(\n",
    "            batch[\"target_text\"],\n",
    "            max_length=max_target_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"np\"\n",
    "        )\n",
    "        model_inputs[\"labels\"]= labels[\"input_ids\"]\n",
    "        return model_inputs\n",
    "\n",
    "train_tokenized=train_ds.map(preprocess,batched=True,remove_columns=train_ds.column_names)\n",
    "val_tokenized=val_ds.map(preprocess,batched=True,remove_columns=val_ds.column_names)\n",
    "data_collator=DataCollatorForSeq2Seq(tokenizer,model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1513d4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sofiazogkza/repos/Ironhack/Ironhack Lab/Week 6/D2/automated-customer-reviews/venvSofia/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:01, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3, training_loss=44.897186279296875, metrics={'train_runtime': 2.1934, 'train_samples_per_second': 5.471, 'train_steps_per_second': 1.368, 'total_flos': 2256053207040.0, 'train_loss': 44.897186279296875, 'epoch': 3.0})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args=TrainingArguments(\n",
    "    output_dir=\"../outputs/flan_t5_small_lora_ SANDRA\",\n",
    "\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=3e-4,\n",
    "\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2,\n",
    "\n",
    "    fp16=False,\n",
    ")\n",
    "\n",
    "trainer=Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=val_tokenized,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc99ea39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../outputs/flan_t5_small_lora_ SANDRA/tokenizer_config.json',\n",
       " '../outputs/flan_t5_small_lora_ SANDRA/special_tokens_map.json',\n",
       " '../outputs/flan_t5_small_lora_ SANDRA/spiece.model',\n",
       " '../outputs/flan_t5_small_lora_ SANDRA/added_tokens.json',\n",
       " '../outputs/flan_t5_small_lora_ SANDRA/tokenizer.json')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"../outputs/flan_t5_small_lora_ SANDRA\")\n",
    "tokenizer.save_pretrained(\"../outputs/flan_t5_small_lora_ SANDRA\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77583de",
   "metadata": {},
   "source": [
    "### Predictions with fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4005a854",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path=\"../outputs/flan_t5_small_lora_ SANDRA\"\n",
    "\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_path)\n",
    "model=AutoModelForSeq2SeqLM.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c248c16",
   "metadata": {},
   "source": [
    "Run a Test-Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4d059a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an excellent product guide. Write a short , clear, helpful and fact- based buying guide.\n",
      "\n",
      "Write an article based on these rules below:\n",
      "1. Use only the information provided in the structured data.\n",
      "2. Recommend the top 3 products.\n",
      "3. Show your results in the following order: category, product, average rating, positive reviews, and a short summary about the product. Mentioning why a certain  \n",
      "---Model Output---\n",
      "\n",
      "Product:AmazonBasics AA Performance Alkaline Batteries (48 Count) - Packaging May Vary (Brand:AmazonBasics) - Average rating: 4.45 from 8343 review. - Product:AmazonBasics AAA Performance Alkaline Batteries (36 Count) - Packaging May Vary (Brand:AmazonBasics) - Average rating: 4.45 from 8343 review. - Product:AmazonBasics AAA Performance Alkaline Batteries\n"
     ]
    }
   ],
   "source": [
    "row=articles_df.iloc[0]\n",
    "cluster_summary=row[\"cluster_summary\"]\n",
    "\n",
    "prompt=f\"\"\"\n",
    "You are an excellent product guide. Write a short , clear, helpful and fact- based buying guide.\n",
    "\n",
    "Write an article based on these rules below:\n",
    "1. Use only the information provided in the structured data.\n",
    "2. Recommend the top 3 products.\n",
    "3. Show your results in the following order: category, product, average rating, positive reviews, and a short summary about the product. Mentioning why a certain product is especially good or either bad, based on customer reviews.\n",
    "4. For each recommended product, write a summary of all positive reviews about the product in 2 short sentences.\n",
    "5. When mentioning products to avoid use neutral language and data- based statements. \n",
    "6. Never claim general brand quality.\n",
    "\n",
    "Here is the structured data for the next cluster: \n",
    " {cluster_summary}\n",
    "\n",
    "Now kindly write the article:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "inputs=tokenizer(prompt,return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    output=model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=120,\n",
    "        num_beams=3\n",
    "    )\n",
    "\n",
    "print(prompt[:400],\"\\n---Model Output---\\n\")\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ecea72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category:Cluster Batteries\n",
      "\n",
      "Top products:\n",
      "\n",
      "-Product:AmazonBasics AA Performance Alkaline Batteries (48 Count) - Packaging May Vary (Brand:Amazonbasics)\n",
      "  -Average rating: 4.45 from3728 review.\n",
      "  -Positive reviews: 100.0%.\n",
      "\n",
      "\n",
      "\n",
      "-Product:AmazonBasics AAA Performance Alkaline Batteries (36 Count) (Brand:Amazonbasics)\n",
      "  -Average rating: 4.45 from8343 review.\n",
      "  -Positive reviews: 0.0%.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Product to avoid:\n",
      "\n",
      "-Product:AmazonBasics AAA Performance Alkaline Batteries (36 Count) (Brand:Amazonbasics)\n",
      "  -Average rating: 4.45 from8343 review.\n",
      "  -Positive reviews: 0.0%.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cluster_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c11219b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Name    Amazon - Echo Plus w/ Built-In Hub - Silver\n",
      "avg_rating                                         4.749153\n",
      "pos_frac                                                1.0\n",
      "neg_frac                                                0.0\n",
      "num_reviews                                             590\n",
      "Name: 31, dtype: object\n",
      "sentiment\n",
      "positive    1.0\n",
      "Name: proportion, dtype: float64\n",
      "sentiment\n",
      "positive    590\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "prod=top_df.iloc[1]\n",
    "pid=prod[\"ProductID\"]\n",
    "\n",
    "print(prod[[\"Product Name\",\"avg_rating\",\"pos_frac\",\"neg_frac\",\"num_reviews\"]])\n",
    "\n",
    "rows=df[df[\"ProductID\"]==pid]\n",
    "print(rows[\"sentiment\"].value_counts(normalize=True))\n",
    "print(rows[\"sentiment\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dae3109a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category:Cluster Batteries\n",
      "\n",
      "Top products:\n",
      "\n",
      "-Product:AmazonBasics AA Performance Alkaline Batteries (48 Count) - Packaging May Vary (Brand:Amazonbasics)\n",
      "  -Average rating: 4.45 from3728 review.\n",
      "  -Positive reviews: 100.0%.\n",
      "\n",
      "\n",
      "\n",
      "-Product:AmazonBasics AAA Performance Alkaline Batteries (36 Count) (Brand:Amazonbasics)\n",
      "  -Average rating: 4.45 from8343 review.\n",
      "  -Positive reviews: 0.0%.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Product to avoid:\n",
      "\n",
      "-Product:AmazonBasics AAA Performance Alkaline Batteries (36 Count) (Brand:Amazonbasics)\n",
      "  -Average rating: 4.45 from8343 review.\n",
      "  -Positive reviews: 0.0%.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cluster_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1961379",
   "metadata": {},
   "source": [
    "Key Learning of M3\n",
    "Prompting in Flan Model- it is extremely sensitive to constraints like \n",
    "max. of two sentences\n",
    "use only factual information\n",
    "only use structured data\n",
    "If the rules are too strict, the model will hallucinate strongly. Avoid strict wording.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9495663",
   "metadata": {},
   "source": [
    "# Review of FLAN-T5 Results\n",
    "\n",
    "- Pipeline successfully generates buying guides per cluster from review data.  \n",
    "- `cluster_summary` lists top products and product to avoid accurately.  \n",
    "- Generated `article` outputs are factually correct but sometimes too short or repetitive.  \n",
    "- Summaries often miss the full 2-sentence detail per product.  \n",
    "- Recommendations: refine prompts, clean inputs, and optionally fine-tune with LoRA for better formatting and completeness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846705e0",
   "metadata": {},
   "source": [
    "| Cluster Value          | Cluster Name              | Top Products (Summary)                                                                                          | Product to Avoid / Article Summary                                      |\n",
    "|------------------------|---------------------------|---------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------|\n",
    "| Batteries              | Cluster Batteries         | AmazonBasics AA 48 Count, rating 4.45, 100% positive reviews<br>AmazonBasics AAA 36 Count, rating 4.45, 0% | AmazonBasics AAA 36 Count, rating 4.45<br>Summary: Rated 4.45          |\n",
    "| Classic Fire Tablets   | Cluster Classic Fire Tablets | Kindle Voyage 4GB, rating 4.72, 100% positive<br>Kindle Fire 16GB, rating 4.60, 100% positive<br>Fire Kids Edition 16GB, rating 4.53, 100% | Fire Tablet 8GB, rating 4.45<br>Summary: Kindle Fire 16GB has 4.72 rating |\n",
    "| Fire HD Tablets        | Cluster Fire HD Tablets   | PowerFast USB Charger, rating 4.86, 100% positive<br>Fire HD 8 Tablet 32GB, rating 4.67, 100% positive<br>PowerFast USB Charger, rating 4.67, 100% | Fire HD 8 Tablet 16GB, rating 4.58<br>Summary: Fire HD 8 Tablet 32GB recommended |\n",
    "| Kindle E-readers       | Cluster Kindle E-readers  | Kindle Voyage E-reader, rating 4.89, 100% positive<br>Kindle Fire 16GB, rating 4.86, 100% positive<br>Fire Tablet 8GB, rating 4.82, 100% | Kindle E-reader Black, rating 4.43<br>Summary: 3 of 5 Kindle Fire E-readers are best |\n",
    "| Smart Home / Audio     | Cluster Smart Home / Audio | Fire HD 10 Tablet 16GB, rating 4.77, 100% positive<br>Echo Plus, rating 4.75, 100% positive<br>Amazon Tap, rating 4.73, 100% | Amazon Tap Portable Speaker, rating 4.51<br>Summary: Fire HD 10 Tablet recommended |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvSofia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
